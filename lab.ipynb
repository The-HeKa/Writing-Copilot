{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-21 17:35:44.119621: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "/home/yuan/anaconda3/envs/wtcpt/lib/python3.8/site-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:903: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  warnings.warn(\"`tf.nn.rnn_cell.LSTMCell` is deprecated and will be \"\n",
      "/home/yuan/anaconda3/envs/wtcpt/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n",
      "2023-01-21 17:35:46.081003: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-01-21 17:35:46.093271: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-01-21 17:35:46.264952: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-01-21 17:35:46.265007: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (MSI): /proc/driver/nvidia/version does not exist\n",
      "2023-01-21 17:35:47.466119: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-21 17:35:47.469289: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-01-21 17:35:47.501233: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
      "2023-01-21 17:35:47.582740: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2688000000 Hz\n",
      "2023-01-21 17:35:52.083935: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import opencc\n",
    "from ckiptagger import WS, POS\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "converter = opencc.OpenCC('s2tw.json')\n",
    "converter_ = opencc.OpenCC('tw2sp.json')\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# ws = WS(\"./data\", disable_cuda= False)\n",
    "# pos = POS(\"./data\",disable_cuda= False)\n",
    "\n",
    "ws = WS(\"./data\")\n",
    "pos = POS(\"./data\")\n",
    "\n",
    "# cn_version\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['傅达仁今运行安乐死，爆出自己20年前遭纬来体育台封杀，他懂自己哪里得罪到电视台。', '傅达仁今将运行安乐死，却突然爆出自己20年前遭纬来体育台封杀，他不懂自己哪里得罪到电视台。'], ['000010000010000000000000000010000000000', '00000100000010100000000000000000010000000000'], [['傅达仁今MASK运行安乐死，却突然爆出自己20年前遭纬来体育台封杀，他不懂自己哪里得罪到电视台。', '傅达仁今将运行安乐死，却突然爆出自己20年前遭纬来体育台封杀，他不懂自己哪里得罪到电视台。'], ['傅达仁今将运行安乐死，MASK突然爆出自己20年前遭纬来体育台封杀，他不懂自己哪里得罪到电视台。', '傅达仁今将运行安乐死，却突然爆出自己20年前遭纬来体育台封杀，他不懂自己哪里得罪到电视台。'], ['傅达仁今将运行安乐死，却MASK爆出自己20年前遭纬来体育台封杀，他不懂自己哪里得罪到电视台。', '傅达仁今将运行安乐死，却突然爆出自己20年前遭纬来体育台封杀，他不懂自己哪里得罪到电视台。'], ['傅达仁今将运行安乐死，却突然爆出自己20年前遭纬来体育台封杀，他MASK懂自己哪里得罪到电视台。', '傅达仁今将运行安乐死，却突然爆出自己20年前遭纬来体育台封杀，他不懂自己哪里得罪到电视台。']])\n"
     ]
    }
   ],
   "source": [
    "# generate mask and label\n",
    "def word(sentence,tag_pos,_p):\n",
    "\n",
    "    '''\n",
    "    Inputs:\n",
    "        label(['傅達仁今將執行安樂死，卻突然爆出自己20年前遭緯來體育台封殺，他不懂自己哪裡得罪到電視台。'],'D',0.5)\n",
    "\n",
    "    Outputs\n",
    "        (['傅达仁今运行安乐死，爆出自己20年前遭纬来体育台封杀，他懂自己哪里得罪到电视台。', '傅达仁今运行安乐死，爆出自己20年前遭纬来体育台封杀，他懂自己哪里得罪到电视台。'], \n",
    "        ['000010000010000000000000000010000000000', '000000000000000000000000000000000000000'], \n",
    "        [['傅达仁今MASK运行安乐死，却突然爆出自己20年前遭纬来体育台封杀，他不懂自己哪里得罪到电视台。', '傅达仁今将运行安乐死，却突然爆出自己20年前遭纬来体育台封杀，他不懂自己哪里得罪到电视台。'], \n",
    "         ['傅达仁今将运行安乐死，MASK突然爆出自己20年前遭纬来体育台封杀，他不懂自己哪里得罪到电视台。', '傅达仁今将运行安乐死，却突然爆出自己20年前遭纬来体育台封杀，他不懂自己哪里得罪到电视台。'], \n",
    "         ['傅达仁今将运行安乐死，却MASK爆出自己20年前遭纬来体育台封杀，他不懂自己哪里得罪到电视台。', '傅达仁今将运行安乐死，却突然爆出自己20年前遭纬来体育台封杀，他不懂自己哪里得罪到电视台。'], \n",
    "         ['傅达仁今将运行安乐死，却突然爆出自己20年前遭纬来体育台封杀，他MASK懂自己哪里得罪到电视台。', '傅达仁今将运行安乐死，却突然爆出自己20年前遭纬来体育台封杀，他不懂自己哪里得罪到电视台。']])\n",
    "    '''\n",
    "\n",
    "    sents = []\n",
    "    labels = []\n",
    "\n",
    "    sentence = converter.convert(sentence[0])\n",
    "    sentence_list = [sentence]\n",
    "    word_sentence_list = ws(sentence_list)\n",
    "    pos_sentence_list = pos(word_sentence_list)\n",
    "\n",
    "    label_list = []\n",
    "\n",
    "    for i in range(len(word_sentence_list)):\n",
    "        for r in range(len(word_sentence_list[i])):\n",
    "            word_ = word_sentence_list[i][r]\n",
    "            pos_ = pos_sentence_list[i][r]\n",
    "\n",
    "            label_list.append([word_,pos_])\n",
    "    sent = ''.join([i[0] for i in label_list])\n",
    "    # get tag's next word's position\n",
    "    def get_key_label(val):\n",
    "        result = []\n",
    "        position = 0\n",
    "        del_list = []\n",
    "        for i in range(len(label_list)):\n",
    "            key, value = label_list[i]\n",
    "            position += len(key)\n",
    "            \n",
    "            if val == value:\n",
    "\n",
    "                # print(len(key),position)\n",
    "                result.append([len(key),position])\n",
    "                \n",
    "        return result, sent\n",
    "    \n",
    "\n",
    "    # get tag's next word's position\n",
    "    def get_key_mask(val):\n",
    "        result = []\n",
    "        position = 0\n",
    "        for i in range(len(label_list)):\n",
    "            key, value = label_list[i]\n",
    "            position += len(key)\n",
    "            \n",
    "            if val == value:\n",
    "                start_pos = position - len(key)\n",
    "                end_pos = position-1\n",
    "\n",
    "                sent = converter_.convert(sentence[:start_pos]+'MASK'+sentence[end_pos+1:])\n",
    "                token = converter_.convert(sent.replace('MASK', sentence[start_pos:end_pos+1]))\n",
    "                result.append([sent, token])\n",
    "     \n",
    "        return result\n",
    "\n",
    "    mask = get_key_mask(tag_pos)\n",
    "\n",
    "    for p in _p:\n",
    "        sent = converter_.convert(sent)\n",
    "\n",
    "        label_tag, _sent = get_key_label(tag_pos)\n",
    "        for x in range(len(label_tag)):\n",
    "            p_ = random.randint(1,100)/100\n",
    "            if p_ <= p:\n",
    "                # 保留\n",
    "                pass\n",
    "            else:\n",
    "                # 刪除\n",
    "                for _ in range(label_tag[x][0]):\n",
    "                    _sent = list(_sent)\n",
    "                    _sent[label_tag[x][1]-_-1] = '|'\n",
    "                    _sent = ''.join(_sent)\n",
    "\n",
    "        for k in range(len(label_tag)):\n",
    "            x_ = _sent[:label_tag[k][1]]\n",
    "            count = 0\n",
    "            for d in x_:\n",
    "                if d == '|': count +=1\n",
    "            label_tag[k][1] -= count\n",
    "\n",
    "        _sent = _sent.replace('|','')\n",
    "        label_tag = [j[1] for j in label_tag]\n",
    "                \n",
    "        # 先將_sent編碼成0陣列，再根據label_tag把部分的0換成1\n",
    "        encoded_str = tokenizer(_sent, padding=True, truncation=True) \n",
    "        tokens = tokenizer.convert_ids_to_tokens(encoded_str.input_ids)\n",
    "        lengh = len(tokens[1:-1])\n",
    "        label = ''\n",
    "        while len(label)<lengh:\n",
    "            label+='0'\n",
    "        label = list(label)\n",
    "        for i in label_tag:\n",
    "            label[i] = '1'\n",
    "        label = ''.join(label)\n",
    "\n",
    "        labels.append(label)\n",
    "        sents.append(_sent)\n",
    "\n",
    "    return sents, labels, mask\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(word(['傅達仁今將執行安樂死，卻突然爆出自己20年前遭緯來體育台封殺，他不懂自己哪裡得罪到電視台。'],'D',[0.1,0.9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['傅达仁今MASK运行安乐死，却突然爆出自己20年前遭纬来体育台封杀，他不懂自己哪里得罪到电视台。', '将'],\n",
       " ['傅达仁今将运行安乐死，MASK突然爆出自己20年前遭纬来体育台封杀，他不懂自己哪里得罪到电视台。', '却'],\n",
       " ['傅达仁今将运行安乐死，却MASK爆出自己20年前遭纬来体育台封杀，他不懂自己哪里得罪到电视台。', '突然'],\n",
       " ['傅达仁今将运行安乐死，却突然爆出自己20年前遭纬来体育台封杀，他MASK懂自己哪里得罪到电视台。', '不']]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_mask(['傅達仁今將執行安樂死，卻突然爆出自己20年前遭緯來體育台封殺，他不懂自己哪裡得罪到電視台。'],'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chenyu(sent, chenyu, p):\n",
    "    '''\n",
    "    Inputs:\n",
    "        chenyu('细致地挨门逐户去调查访问。','挨门逐户', 0.1)\n",
    "    \n",
    "    Ouputs:\n",
    "        (['细致MASK查访问。', '细致地挨门逐户去调查访问。'], ['细致查访问。', '001000'])\n",
    "    '''\n",
    "    mask = ''\n",
    "    label = [] \n",
    "\n",
    "    front_random = random.randint(0,3)\n",
    "    back_random = random.randint(0,3)\n",
    "    chenyu_pos = sent.find(chenyu)\n",
    "    tag = sent[chenyu_pos-front_random:chenyu_pos+back_random+len(chenyu)+1]\n",
    "    mask = [sent.replace(tag,'MASK'), sent]\n",
    "\n",
    "    p_ = random.randint(1,100)/100\n",
    "    if p_ <= p:\n",
    "        # 保留\n",
    "        label_tag = chenyu_pos+back_random+len(chenyu)\n",
    "    else:\n",
    "        # 刪除\n",
    "        sent = mask[0].replace('MASK','')\n",
    "        label_tag = mask[0].find('MASK')\n",
    "\n",
    "    encoded_str = tokenizer(sent, padding=True, truncation=True) \n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoded_str.input_ids)\n",
    "    lengh = len(tokens[1:-1])\n",
    "    label = ''\n",
    "    while len(label)<lengh:\n",
    "        label+='0'\n",
    "    label = list(label)\n",
    "    label[label_tag] = '1'\n",
    "    label = ''.join(label)\n",
    "\n",
    "    return mask, [sent,label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['细MASK调查访问。', '细致地挨门逐户去调查访问。'], ['细调查访问。', '010000'])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chenyu('细致地挨门逐户去调查访问。','挨门逐户', 0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wtcpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4afa11a65da338f3b8d43814e48d0d156a2819e630ba4c0a65e63d83e3f721f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
