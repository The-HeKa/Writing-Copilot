{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 14:04:48.788406: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myuanlu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from simpletransformers.classification import MultiLabelClassificationModel, MultiLabelClassificationArgs\n",
    "from simpletransformers.t5 import T5Model, T5Args\n",
    "from simpletransformers.seq2seq import Seq2SeqModel, Seq2SeqArgs\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import csv\n",
    "import wandb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'chenyu_51657'\n",
    "\n",
    "class data:\n",
    "    def __init__(self, file_name) -> None:\n",
    "\n",
    "        self.task_type = folder_name.split('_')[0]\n",
    "        self.file_name = file_name.replace('.csv','')\n",
    "        self.file_path = folder_name+'/'+self.file_name+'.csv'\n",
    "        self.type = self.file_name.split('_')[0]\n",
    "\n",
    "        self.random_state = 96\n",
    "        self.max_sample = 5000\n",
    "\n",
    "        if self.type == 'label':\n",
    "\n",
    "            self.p = float(self.file_name.split('_')[1])\n",
    "            self.len = int(self.file_name.split('_')[2])\n",
    "\n",
    "            with open(self.file_path, mode = 'r') as f:\n",
    "                self.data = pd.DataFrame([[i[0],list([int(r) for r in i[1]])] for i in csv.reader(f)])\n",
    "                self.data.columns = ['text', 'labels']\n",
    "            \n",
    "            self.wandb_job = '{}_{}'.format(self.task_type, self.file_name)\n",
    "            self.output_dir = 'outputs/'+self.task_type+'/'+self.file_name+'/'\n",
    "\n",
    "            self.data = shuffle(self.data, random_state=self.random_state)\n",
    "            self.data.reset_index(inplace=True, drop=True)\n",
    "            self.data = self.data[:self.max_sample]\n",
    "\n",
    "            self.train, self.test = train_test_split(self.data, test_size=0.2, random_state=self.random_state)\n",
    "            del self.data\n",
    "\n",
    "            self.label_train()\n",
    "              \n",
    "        elif self.type == 'mask':\n",
    "\n",
    "            self.p = 1.0\n",
    "            self.len = int(self.file_name.split('_')[1])\n",
    "\n",
    "            with open(self.file_path, mode = 'r') as f:\n",
    "                self.data = pd.DataFrame([[str(i[0]), str(i[1])] for i in csv.reader(f)]).astype('string')\n",
    "                self.data.columns = [\"input_text\", \"target_text\"]\n",
    "            \n",
    "            self.wandb_job = '{}_{}'.format(self.task_type, self.file_name)\n",
    "            self.output_dir = 'outputs/'+self.task_type+'/'+self.file_name+'/'\n",
    "            \n",
    "            self.data = shuffle(self.data, random_state=self.random_state)\n",
    "            self.data.reset_index(inplace=True, drop=True)\n",
    "            self.data = self.data[:self.max_sample]\n",
    "\n",
    "            self.train, self.test = train_test_split(self.data, test_size=0.2, random_state=self.random_state)\n",
    "            self.train, self.eval = train_test_split(self.train, test_size=0.2, random_state=self.random_state)\n",
    "            del self.data\n",
    "\n",
    "            self.mask_train()\n",
    "    \n",
    "\n",
    "    def label_train(self):\n",
    "        # Optional model configuration\n",
    "        model_args = MultiLabelClassificationArgs(num_train_epochs=2)\n",
    "        model_args.wandb_project = self.wandb_job\n",
    "        model_args.output_dir = self.output_dir\n",
    "\n",
    "\n",
    "        # Create a MultiLabelClassificationModel\n",
    "        model = MultiLabelClassificationModel(\n",
    "            \"bert\",\n",
    "            \"bert-base-chinese\",\n",
    "            num_labels=self.len,\n",
    "            args=model_args\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        model.train_model(self.train)\n",
    "        self.model = model\n",
    "\n",
    "        # Evaluate the model\n",
    "        result, model_outputs, wrong_predictions = model.eval_model(\n",
    "            self.test\n",
    "        )\n",
    "\n",
    "    \n",
    "    def mask_train(self):\n",
    "        # Configure the model\n",
    "        model_args = Seq2SeqArgs()\n",
    "        model_args.num_train_epochs = 2\n",
    "        model_args.evaluate_generated_text = True\n",
    "        model_args.output_dir = self.output_dir\n",
    "        model_args.wandb_project = self.wandb_job\n",
    "        model_args.evaluate_during_training = True\n",
    "        model_args.evaluate_during_training_verbose = True\n",
    "\n",
    "        model = Seq2SeqModel(\n",
    "            'bert',\n",
    "            'bert-base-chinese',\n",
    "            'bert-base-chinese',\n",
    "            args=model_args,\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        model.train_model(self.train, eval_data = self.eval)\n",
    "        self.model = model\n",
    "\n",
    "        # Evaluate the model\n",
    "        result = self.model.eval_model(self.test)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "mask = data('mask_64.csv')\n",
    "mask.model.predict(mask.test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wtcpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4afa11a65da338f3b8d43814e48d0d156a2819e630ba4c0a65e63d83e3f721f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
